{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 4: Improved Network Architectures\n",
    "\n",
    "### Outcomes\n",
    "* **Understand and apply ReLU and LeakyReLU activations** to address vanishing gradient problems and enhance network convergence.\n",
    "* **Implement batch and layer normalization** to stabilize training and improve network performance.\n",
    "* **Analyze and utilize residual connections** to enable deeper network architectures by mitigating vanishing gradient issues.\n",
    "\n",
    "### Readings and Videos\n",
    "* Read Sections 6.1-6.4 from Inside Deep Learning\n",
    "* **Course Notebooks with Videos** Open each of the notebooks included the lesson folder and watch the embedded video. You can read along and work through the code examples as you want. The notebooks are numbered in the order they should be used.\n",
    "\n",
    "### Assessments\n",
    "* Complete the reading quiz in Canvas (10 points).\n",
    "* Complete the exercises in your the homework notebook in CoCalc (40 points)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
